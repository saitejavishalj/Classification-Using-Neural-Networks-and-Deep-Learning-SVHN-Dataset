# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15FsMbNp3AWNZWr2WWzdma6CJoK_UrIiK
"""

import scipy.io as io
from scipy.io import loadmat
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D
from matplotlib import pyplot as plt

####Step1
##Loading the data using Scipy
trX = io.loadmat('/content/drive/MyDrive/SML_project3/test_32x32.mat')
trY = io.loadmat('/content/drive/MyDrive/SML_project3/test_32x32.mat')
tsX = io.loadmat('/content/drive/MyDrive/SML_project3/test_32x32.mat')
tsY = io.loadmat('/content/drive/MyDrive/SML_project3/test_32x32.mat')

##Training data-Images
trX_arr = np.array(trX['X'])
#Training labels
trY_arr = np.array(trY['y'])

##Testing data-Images
tsX_arr = np.array(tsX['X'])
#Testing labels
tsY_arr = np.array(tsY['y'])

print(trX_arr.shape)

trX_arr = trX_arr.astype('float64')
tsX_arr = tsX_arr.astype('float64')


####Step2
##Normalizing the pixel values between 0 and 1
trX_arr /= 255.0
tsX_arr /= 255.0
# trX_arr = layers.experimental.preprocessing.Rescaling(1.0/255)(trX_arr)
# tsX_arr = layers.experimental.preprocessing.Rescaling(1.0/255)(tsX_arr)

##One-hot encoding using Sklearn.preprocessing
trY_arr = trY_arr.astype('int64')
tsY_arr = tsY_arr.astype('int64')
from sklearn.preprocessing import LabelBinarizer
encoder = LabelBinarizer()
trY_arr_en = encoder.fit_transform(trY_arr)
tsY_arr_en = encoder.fit_transform(tsY_arr)
print(tsY_arr_en)


####Step3
###Implement the CNN model as per the archetecture, below are the steps
model_ = Sequential()

##Architecture 1
model_.add(Conv2D(64, (5,5), strides=(1,1), padding='same', activation='relu', data_format='channels_last'))

##Architecture 2
model_.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', data_format=None))

##Architecture 3
model_.add(Conv2D(64, (5,5), strides=(1,1), padding='same', activation='relu', data_format='channels_last'))

##Architecture 4
model_.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', data_format=None))

##Architecture 5
model_.add(Conv2D(128, (5,5), strides=(1,1), padding='same', activation='relu', data_format='channels_last'))


###Now after the CNN Model, the fully connected layers start from here
model_.add(Flatten())
##Architecture 6
model_.add(layers.Dense(3072, activation='relu', use_bias=True))

##Architecture 7
model_.add(layers.Dense(2048, activation='relu', use_bias=True))

model_.add(layers.Dense(10, use_bias=True))
model_.add(layers.Activation('softmax'))


####Step4
###Compile the model using SGD Optimizer with Learning rate = 0.01
opt = keras.optimizers.SGD(learning_rate=0.01, momentum=0.5)
model_.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

###Train the model here with a batch size of 128, over 20 epochs
##Fit the model
history = model_.fit(trX_arr, trY_arr_en, batch_size=128, epochs=20, validation_data=(tsX_arr, tsY_arr_en))

##History variable will contain accuaracy and loss for every epoch of all the training and validation data
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

train_loss = history.history['loss']
val_loss = history.history['val_loss']

####Step5
###Plotting the training and testing graphs here for every epoch
epochs = []
for i in range(20):
  epochs.append(int(i+1))
print(epochs)
plt.figure(figsize=(15,4))
plt.subplot(1,2,1)
plt.plot(epochs, train_loss, label = 'Training Loss')
plt.plot(epochs, val_loss, label = 'Testing Loss')
plt.gca().get_xaxis().get_major_formatter().set_useOffset(False)
plt.draw()
plt.title("Ploting Losses per epoch")
plt.legend()

plt.subplot(1,2,2)
plt.plot(epochs, train_accuracy, label='Training Accuracy')
plt.plot(epochs, val_accuracy, label='Testing Accuracy')
plt.gca().get_xaxis().get_major_formatter().set_useOffset(False)
plt.draw()
plt.title("Ploting Accuracies per epoch")
plt.legend()

###Evaluating the model on the test data, with a batch size of 32
testing_results = model_.evaluate(x=tsX_arr, y=tsY_arr_en, batch_size=32, verbose=1)

###Printing the Testing loss and testing accuracy
print("Loss = "+"{:.3f}".format(testing_results[0])+"\nClassification Accuracy = "+"{:.3f}".format(testing_results[1]))

